{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utilities.data_preprocessing import separate_per_column, sequencing_data_by_one, extract_features_from_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cleaned dataset and return raw train and test data\n",
    "\n",
    "Because I had to delete the dataset (because of its size) we need to start with the original uncleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to have any dataset looking like the following image. this is make it easier to preprocess the data to all the models, in wich we just need to call the functions on /utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Forma do dataset após limpeza e preparação para processamento](data/PAMAP2_cleaned_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading the dataset and put the data separeted per subject in the following folder\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/231/pamap2+physical+activity+monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_original = \"data/PAMAP2_Dataset_original/\"\n",
    "s_1 = \"subject101.dat\"\n",
    "s_2 = \"subject102.dat\"\n",
    "s_3 = \"subject103.dat\"\n",
    "s_4 = \"subject104.dat\"\n",
    "s_5 = \"subject105.dat\"\n",
    "s_6 = \"subject106.dat\"\n",
    "s_7 = \"subject107.dat\"\n",
    "s_8 = \"subject108.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_df = pd.read_csv(data_path_original + s_1, sep=\" \", header=None)\n",
    "s2_df = pd.read_csv(data_path_original + s_2, sep=\" \", header=None)\n",
    "s3_df = pd.read_csv(data_path_original + s_3, sep=\" \", header=None)\n",
    "s4_df = pd.read_csv(data_path_original + s_4, sep=\" \", header=None)\n",
    "s5_df = pd.read_csv(data_path_original + s_5, sep=\" \", header=None)\n",
    "s6_df = pd.read_csv(data_path_original + s_6, sep=\" \", header=None)\n",
    "s7_df = pd.read_csv(data_path_original + s_7, sep=\" \", header=None)\n",
    "s8_df = pd.read_csv(data_path_original + s_8, sep=\" \", header=None)\n",
    "\n",
    "array_of_subjects = [s1_df, s2_df, s3_df, s4_df, s5_df, s6_df, s7_df, s8_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_Subject):\n",
    "    new_df = df_Subject.copy()\n",
    "    new_df = new_df.drop(new_df.columns[13:], axis=1)\n",
    "    new_df = new_df.ffill()\n",
    "    new_df = new_df.rename(\n",
    "        columns={\n",
    "            0: \"timestamp\",\n",
    "            1: \"activity\",\n",
    "            2: \"bpm\",\n",
    "            3: \"temp(C)\",\n",
    "            7: \"x-accel\",\n",
    "            8: \"y-accel\",\n",
    "            9: \"z-accel\",\n",
    "            10: \"x-gyro\",\n",
    "            11: \"y-gyro\",\n",
    "            12: \"z-gyro\",\n",
    "        }\n",
    "    )\n",
    "    new_df = new_df.drop(new_df.columns[[4, 5, 6]], axis=1)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for idx, df in enumerate(array_of_subjects):\n",
    "    returned_df = clean_data(df)\n",
    "    returned_df[\"userID\"] = idx + 1\n",
    "    combined_df = pd.concat([combined_df, returned_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "      <th>bpm</th>\n",
       "      <th>temp(C)</th>\n",
       "      <th>x-accel</th>\n",
       "      <th>y-accel</th>\n",
       "      <th>z-accel</th>\n",
       "      <th>x-gyro</th>\n",
       "      <th>y-gyro</th>\n",
       "      <th>z-gyro</th>\n",
       "      <th>userID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.43954</td>\n",
       "      <td>8.76165</td>\n",
       "      <td>3.35465</td>\n",
       "      <td>-0.092217</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.39494</td>\n",
       "      <td>8.55081</td>\n",
       "      <td>3.64207</td>\n",
       "      <td>-0.024413</td>\n",
       "      <td>0.047759</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  activity    bpm  temp(C)  x-accel  y-accel  z-accel    x-gyro  \\\n",
       "0       8.38         0  104.0     30.0  2.43954  8.76165  3.35465 -0.092217   \n",
       "1       8.39         0  104.0     30.0  2.39494  8.55081  3.64207 -0.024413   \n",
       "\n",
       "     y-gyro    z-gyro  userID  \n",
       "0  0.056812 -0.015845       1  \n",
       "1  0.047759  0.006474       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It should have the same columns as the image\n",
    "combined_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sava the dataset\n",
    "combined_df.to_csv(\"data/PAMAP2_cleaned_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the loading of the same cleaned dataset as above\n",
    "data_path = \"data/PAMAP2_cleaned_dataset.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the original cleaned dataset\n",
    "__Drop unnecessary columns and a few activities__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3 12 13  5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>x-accel</th>\n",
       "      <th>y-accel</th>\n",
       "      <th>z-accel</th>\n",
       "      <th>x-gyro</th>\n",
       "      <th>y-gyro</th>\n",
       "      <th>z-gyro</th>\n",
       "      <th>userID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.46791</td>\n",
       "      <td>-1.68076</td>\n",
       "      <td>1.15480</td>\n",
       "      <td>-0.008240</td>\n",
       "      <td>-0.029004</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-9.46778</td>\n",
       "      <td>-1.74110</td>\n",
       "      <td>1.23043</td>\n",
       "      <td>0.054293</td>\n",
       "      <td>-0.001861</td>\n",
       "      <td>-0.023345</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity  x-accel  y-accel  z-accel    x-gyro    y-gyro    z-gyro  userID\n",
       "0         1 -9.46791 -1.68076  1.15480 -0.008240 -0.029004  0.002536       8\n",
       "1         1 -9.46778 -1.74110  1.23043  0.054293 -0.001861 -0.023345       8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_2drop = [\"timestamp\", \"bpm\", \"temp(C)\"]\n",
    "data = data.drop(columns_2drop, axis=1)\n",
    "\n",
    "activities_2drop = [0, 4, 6, 7, 10, 11, 16, 17, 18, 19, 20, 24]\n",
    "data = data[~data['activity'].isin(activities_2drop)].reset_index(drop=True)\n",
    "\n",
    "print(data[\"activity\"].unique())\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving for training and test\n",
    "\n",
    "Para treino, aqui, selecionei apenas os userID de 1 a 3 e deixei o 8 para teste (para não ocupar muito espaço e ser mais rápido no processamento).\n",
    "\n",
    "Nos modelos que eu treinei, cujo os dados estão no ppt, usei para treino os user de 1 a 7 e deixei o 8 para teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train são os users: [3 2 1]\n",
      "data_test são os users: [8]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>x-accel</th>\n",
       "      <th>y-accel</th>\n",
       "      <th>z-accel</th>\n",
       "      <th>x-gyro</th>\n",
       "      <th>y-gyro</th>\n",
       "      <th>z-gyro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.25869</td>\n",
       "      <td>5.42474</td>\n",
       "      <td>7.86577</td>\n",
       "      <td>-0.149700</td>\n",
       "      <td>0.075643</td>\n",
       "      <td>0.126064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.42397</td>\n",
       "      <td>5.42599</td>\n",
       "      <td>7.92634</td>\n",
       "      <td>-0.153853</td>\n",
       "      <td>0.061406</td>\n",
       "      <td>0.097976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity  x-accel  y-accel  z-accel    x-gyro    y-gyro    z-gyro\n",
       "0         1 -1.25869  5.42474  7.86577 -0.149700  0.075643  0.126064\n",
       "1         1 -1.42397  5.42599  7.92634 -0.153853  0.061406  0.097976"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data[data['userID'].isin([1,2,3])].reset_index(drop=True)\n",
    "data_test = data[data['userID'].isin([8])].reset_index(drop=True)\n",
    "\n",
    "print(\"data_train são os users:\",data_train[\"userID\"].unique())\n",
    "print(\"data_test são os users:\",data_test[\"userID\"].unique())\n",
    "\n",
    "data_train = data_train.drop(\"userID\", axis=1)\n",
    "data_test = data_test.drop(\"userID\", axis=1)\n",
    "\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\"data/data_raw_train.csv\", index=False)\n",
    "data_test.to_csv(\"data/data_raw_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Train / Test Data, for further processing\n",
    "\n",
    "ps: as atividades do dataset são 1,2,3,5,12,13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/data_raw_train.csv\")\n",
    "data_test = pd.read_csv(\"data/data_raw_test.csv\")\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate per Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_activity_dic[1].shape (72661, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-accel</th>\n",
       "      <th>y-accel</th>\n",
       "      <th>z-accel</th>\n",
       "      <th>x-gyro</th>\n",
       "      <th>y-gyro</th>\n",
       "      <th>z-gyro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.25869</td>\n",
       "      <td>5.42474</td>\n",
       "      <td>7.86577</td>\n",
       "      <td>-0.149700</td>\n",
       "      <td>0.075643</td>\n",
       "      <td>0.126064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.42397</td>\n",
       "      <td>5.42599</td>\n",
       "      <td>7.92634</td>\n",
       "      <td>-0.153853</td>\n",
       "      <td>0.061406</td>\n",
       "      <td>0.097976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x-accel  y-accel  z-accel    x-gyro    y-gyro    z-gyro\n",
       "0 -1.25869  5.42474  7.86577 -0.149700  0.075643  0.126064\n",
       "1 -1.42397  5.42599  7.92634 -0.153853  0.061406  0.097976"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columm_to_separate_by = \"activity\"\n",
    "data_activity_dic = separate_per_column(data_train, columm_to_separate_by)\n",
    "\n",
    "print(\"data_activity_dic[1].shape\", data_activity_dic[1].shape)\n",
    "data_activity_dic[1].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create windows of sequences of the data\n",
    "\n",
    "_Having sequences of data (windows) is necessary to train some generative models._\n",
    "\n",
    "_It's also necessary to be able to extract time and frequency features from the raw data, which is also benefictial to train ML classification models. On the contrary, DL models often can be feed raw data._\n",
    "\n",
    "Esta função vai criar arrays de 3d, o primeiro vai ter as primeiras 6*100 linhas, ou seja de 1 a 600, o segundo vai ter de 2 a 601 e por aí fora. É possivel ajustar o overlap usando a função ``sequencing_data`` (em vez de esta) e passando um overlap de 0 a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of each sequence is 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1075049d0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ml_env_v12/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of windows/sequences: 72061 \n",
      "Number of samples per sequence: 600 \n",
      "Number of features per sequence: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72061, 600, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>>>> EDIT HERE\n",
    "seconds = 6 # Got this value from articles, but I tested with others as well\n",
    "sampling_rate = 100\n",
    "normalize = False\n",
    "\n",
    "print(\"The number of each sequence is\", seconds * sampling_rate)\n",
    "\n",
    "data_act_1_windows = sequencing_data_by_one(data_activity_dic[1], seconds, sampling_rate, normalize)\n",
    "data_act_2_windows = sequencing_data_by_one(data_activity_dic[2], seconds, sampling_rate, normalize)\n",
    "data_act_3_windows = sequencing_data_by_one(data_activity_dic[3], seconds, sampling_rate, normalize)\n",
    "data_act_5_windows = sequencing_data_by_one(data_activity_dic[5], seconds, sampling_rate, normalize)\n",
    "data_act_12_windows = sequencing_data_by_one(data_activity_dic[12], seconds, sampling_rate, normalize)\n",
    "data_act_13_windows = sequencing_data_by_one(data_activity_dic[13], seconds, sampling_rate, normalize)\n",
    "\n",
    "\n",
    "print(\"Number of windows/sequences:\", data_act_1_windows.shape[0], \"\\nNumber of samples per sequence:\", data_act_1_windows.shape[1], \"\\nNumber of features per sequence:\", data_act_1_windows.shape[2])\n",
    "data_act_1_windows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar os dados sequenciados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/sequences/data_train_act_1_windows.npy\", data_act_1_windows)\n",
    "np.save(\"data/sequences/data_train_act_2_windows.npy\", data_act_2_windows)\n",
    "np.save(\"data/sequences/data_train_act_3_windows.npy\", data_act_3_windows)\n",
    "np.save(\"data/sequences/data_train_act_5_windows.npy\", data_act_5_windows)\n",
    "np.save(\"data/sequences/data_train_act_12_windows.npy\", data_act_12_windows)\n",
    "np.save(\"data/sequences/data_train_act_13_windows.npy\", data_act_13_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features from windows\n",
    "\n",
    "__Three options are provided to extract the features:__\n",
    "- 1 - Extract only a selected features that were studied and mentioned on the article:\n",
    "Experience:A Comparative Analysis of Multivariate Time-Series Generative Models: A Case Study on Human Activity Data\n",
    "- 2 - Extract only another selection of features mentioned on article:A study of human activity recognition using adaboost classifiers on WISDM dataset\n",
    "- False - Extract almost all possible features (most likely it will need an extra feature selection step, like using PCA)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Column_names:__\n",
    "\n",
    "_An argument of list[str] must be passed and must include accelerometer and/or gyroscope data (or at least one of them).\n",
    "The name of the data must be like [\"x-accel\", \"y-accel\", \"z-accel\", \"x-gyro\", \"y-gyro\", \"z-gyro\"], this was to simplify the calculation of features. \n",
    "\n",
    "It will only return a df with the computed features. If more features were in the data, they will be lost or the extractions functions need to be modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PreSelected features = 1__\n",
    "- {X, Y, Z} AVG: Average sensor value over the window (per axis).\n",
    "- {X, Y, Z} PEAK: Time in milliseconds between the peaks in the wave associated with most activities. Heuristically determined (per axis).\n",
    "- {X, Y, Z} ABSOLDEV: Average absolute difference between each of the Sequenced readings and the mean of those values (per axis).\n",
    "- {X, Y, Z} STANDDEV: Standard deviation of the Sequenced values (per axis).\n",
    "- RESULTANT: Average resultant value, computed by squaring each matching x, y, and z value, summing them, taking the square root, and then averaging these values over the Sequenced readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Os nomes das colunas devem ser [\"x-accel\", \"y-accel\", \"z-accel\", \"x-gyro\", \"y-gyro\", \"z-gyro\"], na mesma ordem do array\n",
    "\n",
    "column_names = [\"x-accel\", \"y-accel\", \"z-accel\", \"x-gyro\", \"y-gyro\", \"z-gyro\"]\n",
    "preselected_features = 1\n",
    "sampling_rate = 100\n",
    "band = (0.1, 3) # Este também é o valor default, by chatgpt\n",
    "\n",
    "data_act_1_extracted_features = extract_features_from_windows(data_act_1_windows, column_names, preselected_features, sampling_rate, band)\n",
    "data_act_2_extracted_features = extract_features_from_windows(data_act_2_windows, column_names, preselected_features, sampling_rate, band)\n",
    "data_act_3_extracted_features = extract_features_from_windows(data_act_3_windows, column_names, preselected_features, sampling_rate, band)\n",
    "data_act_5_extracted_features = extract_features_from_windows(data_act_5_windows, column_names, preselected_features, sampling_rate, band)\n",
    "data_act_12_extracted_features = extract_features_from_windows(data_act_12_windows, column_names, preselected_features, sampling_rate, band)\n",
    "data_act_13_extracted_features = extract_features_from_windows(data_act_13_windows, column_names, preselected_features, sampling_rate, band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_act_1_extracted_features[\"activity\"] = 1\n",
    "data_act_2_extracted_features[\"activity\"] = 2\n",
    "data_act_3_extracted_features[\"activity\"] = 3\n",
    "data_act_5_extracted_features[\"activity\"] = 5\n",
    "data_act_12_extracted_features[\"activity\"] = 12\n",
    "data_act_13_extracted_features[\"activity\"] = 13\n",
    "\n",
    "data_train_features = pd.concat([data_act_1_extracted_features, data_act_2_extracted_features, data_act_3_extracted_features, data_act_5_extracted_features, data_act_12_extracted_features, data_act_13_extracted_features], axis=0, ignore_index=True)\n",
    "data_train_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_features.to_csv(\"data/features/data_train_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_v12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
